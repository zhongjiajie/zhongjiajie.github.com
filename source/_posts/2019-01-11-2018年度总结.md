---
title: 2018年度总结
date: 2019-01-11 22:21:38
categories:
- 年度总结
---

# 2018年度总结-我还是小学生

今天是2019年1月11日,这是第一次在github page写年度总结,希望这不是最后一次,希望我能坚持下来.2018年是我毕业一来最为复杂的一年,也是最难的一年.好吧一共毕业才1年半,也验证了**成年人的世界里没有容易**这句话.

<!-- more -->

## 2018年历险记

2018年过完春节,我们搬了家,搬家真是各劳神伤财的活.同时因为公司在长沙拿了一个大项目,同时广州的项目接连没有得到用户的认可,我们base广州的几个人被**建议**去长沙或者回公司base杭州发展.基于很多原因考虑,我和同时都选择了长沙,所以2018年春节可以说是我第一次出省工作的一年.

长沙给我的印象是风景很美,人很豪爽,交通相对流畅,还有很辣.我在长沙吃了我人生中第一次放了辣椒的西红柿炒蛋...换了新的环境,接触的东西也多了很多,由于项目原因开始解除java,基于spring和dubbo完成的开发.说实在话,对于一个从python sql学起的非科班码农,java显得特别不友好,一开始最抵触的一点就是参数和结果类型的转换问题,经常因为不知道返回值什么类型但是idea一直提示错误(这里不得不说idea是写java很好的ide).幸亏同事比较友善,很乐意帮我解决我对java的疑问.那段期间我渐渐对java有了一些皮毛的了解,可以看得懂简单的代码了.写了其中一部分小功能.

同时,项目的测试服务器管理放到了我这边,公司有一台外网的测试服务器和四台内网测试服务器,都是从裸机开始搭建的,外网只是用来对外演示用,所以大部分应用,如mysql,zookeeper,rocketmq都是用docker容器+docker-compose部署.期间了写了一键重启docker-compose,一键从gitlab中拉取最新代码更新应用的shell.这大概是我在长沙项目作出的全部贡献了.

长沙的项目做的是应用的中台,目的是实现应用发布平台,下级部门将建设完后,相关人员对应用进行提交,审核,研判,发布工作,后台接口跟踪流程,进度.分析各部门应用的数量,应用使用情况,提供用户对应用评价,建议等功能

7月份事情有了转折,我长期在外出差,女朋友一人和一只狗在广州,加上女朋友刚毕业就遇到37互娱式变态加班,心态有点崩,几次电话都哭泣,我也心感内疚.所以7月就离职走人了.回到广州,想要投简历,遇到之前的同事创业,和之前的工作类似,想了想就去了,从次开启了地狱模式.

工作内容确实类似,都是数据工程,写写sql,规划写数仓数据,但是平台是自己搭的,而且是一个人新搭的.架构从hive+hadoop -> hadoop+yarn+hive -> hadoop+hive+yarn+spark,最后决定了使用spark的STS作为平台的主要入口接收sql,数据同步使用sqoop和datax,平台调度使用airflow.但是spark thrift server确实比hive server弱一点,经常对挂掉,所以平台同事希望将sql转成spark dataframe直接操作HDFS中的数据,然后每个流程用spark-submit提交java类.我肯定是拒绝的,我认为数仓大部分是业务层的东西,理解业务并解决他才是王道,这时候用通用的sql会对实现更加友好;业务层很多东西都是容器改变的,写成java程序打包变更太频繁;数仓的东西高度依赖上下游,如果有业务功能需要在数据流中找一个最优的地方加上业务,如果用spark-submit要去源码中看实现了什么功能然后再加显得十分笨拙;接受部分是spark-submit任务,但是全部切换成spark-submit方式我坚决反对.为此和同事吵了很多次,甚至至今谁都不服谁.

说说目前的项目,项目整体方案使用的是hadoop+yarn+spark+mysql+Elasticsearch+redis+spring boot+react+ArcGIS+echarts这样的解决方案,做的是一个特定行业的内部分析系统,最后给用户使用的是一套数据分析操作,及基础数据结合GIS的展现系统

调度方面开始正式使用airflow,初级是了解airflow是在17年毕业的时候,觉得用代码定义DAG流特别牛叉,平台部署的是使用github上最多start的airflow docker repo,由于业务需要我fork了项目并增加了很多需要的包,制作了自己的镜像部署,部署使用CeleryExecutor+2个worker在单台机器上部署,期间了遇到了很多坑,都爬过来的现在他已经能稳定运行,但是scheduler时间长了会僵死的问题还是没能解决,找遍了社区的方案也只有定时重启这个方法.我个人希望在19年可以对airflow进行较深入的研究,并将我踩过的坑,积累的经验分享到博客.

号外,最近airflow已经成为apache顶级项目了

目前,新公司的项目还在招投标阶段,有中标的希望拿到我在公司的第一个标,同时也是公司的第一个标.但是苦逼的我却要每天熬夜奋战在写投标文件和招标文件.

2018年理财方面可谓一塌糊涂,可谓白打工,最惨的月份甚至是负资产,遥想我毕业的时候还有50K的存款,加上一年半工作的收入.居然会有资产为负数的月份,全靠两张信用卡活到现在.可见2018年花费太多,或者理财过于失败(主要投了个跑路的P2P).2018年让我对现金流水的重要性有了个很好的认识,2019年不求将我18年亏的赚回来,我只求19年不要亏太惨,输少当赢

2019总结起来就是:

* 第一次长期出差工作经历
* 第一次写java生产级项目经历(虽然到现在都不知道dubbo是什么个原理,但是还是完成了上级交的工作)
* 第一次正式工作离职
* 第一次参加创业
* 第一次选择和正式环境下使用airflow
* 第一次亲自参加招标,准备投标
* 第一次在小规模使用spark
* 第一次小规模使用elasticsearch
* 学会了在用户角度考虑产品的发展
* python开始写得比小学生高级一点

## 展望2019年

### 技术展望

* python能从小学生到中学生过度
* java能从新手到小学生过度
* 希望增强基础理论的学习,如数据结构和基本算法
* 加强hadoop家族尤其是spark的学习,跟上时代的步伐
* 静下心看1-2本进阶的书籍,摆脱小学生的能力
* 能热情得投入开源项目的怀抱,积极参加一个较大的开源项目
* 能好好通过wiki积累知识,能通过blog和大家分享我学到的东西
* 整理好github的repo,将类似的repo合并,将没有意义的repo删除

### 生活展望

* 热爱我的生活
* 希望能够乐观地对待这个世界,同时也被这世界善待
* 坚持锻炼,即使每天30分钟也比没有强
* 周末不要睡太晚,早点起床即使不学习也可以运运动,买买菜
* 晚上早点睡觉,争取12点前睡着
* 不求生活给我惊喜,只求它别给我太多惊吓

### 理财展望

* 输少当赢
* 19年年末有存款

### 情感展望

* 希望情感不会被柴米油盐打败
* 待女朋友见家长时,希望双方都喜欢对方
